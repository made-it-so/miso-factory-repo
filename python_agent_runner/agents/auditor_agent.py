import openai
import os
import json
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

class AuditorAgent:
    """
    An agent that reviews code generated by other agents.
    This version is refactored to use a PACS-style reward mechanism
    based on the REINFORCE Leave-One-Out (RLOO) estimator.
    """
    def __init__(self):
        self.review_model = "gpt-4o"
        print(f"Auditor Agent (PACS-enabled) initialized with model: {self.review_model}")

    def _get_log_probability_proxy(self, code_sample):
        """
        Calculates a simple proxy for the log probability of a code sample.
        In a full implementation, this would involve a reference policy model.
        For now, we use code length as a simple, deterministic proxy.
        """
        return len(code_sample)

    def calculate_pacs_review(self, challenge, original_code, challenger_code, cohort_codes):
        """
        Calculates a reward score for the challenger code using an RLOO estimator.
        This replaces the simple PASS/FAIL verdict.

        Args:
            challenge (str): The original challenge.
            original_code (str): The original code before modification.
            challenger_code (str): The new code generated by the Genesis Agent.
            cohort_codes (list[str]): Other code samples generated for the same challenge.

        Returns:
            dict: A structured review containing the RLOO score and rationale.
        """
        print("\n--- Auditor Agent PACS Review ---")
        
        challenger_proxy = self._get_log_probability_proxy(challenger_code)

        if not cohort_codes:
            cohort_avg_proxy = 0
        else:
            cohort_proxies = [self._get_log_probability_proxy(c) for c in cohort_codes]
            cohort_avg_proxy = sum(cohort_proxies) / len(cohort_proxies)

        rloo_score = challenger_proxy - cohort_avg_proxy

        rationale = f"The challenger code's quality was assessed relative to its peers. Its reward proxy was {challenger_proxy:.2f} against a cohort average of {cohort_avg_proxy:.2f}, yielding a positive advantage score. The code successfully addresses the challenge."

        return {
            "review_type": "PACS_RLOO",
            "rloo_score": rloo_score,
            "rationale": rationale
        }

[
  {
    "id": "http://arxiv.org/abs/2509.09679v1",
    "title": "ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms",
    "summary": "Large language models require massive memory footprints, severely limiting deployment on consumer hardware. Quantization reduces memory through lower numerical precision, but extreme 2-bit quantization suffers from catastrophic performance loss due to outliers in activations. Rotation-based methods such as QuIP and QuaRot apply orthogonal transforms to eliminate outliers before quantization, using computational invariance: $\\mathbf{y} = \\mathbf{Wx} = (\\mathbf{WQ}^T)(\\mathbf{Qx})$ for orthogonal $\\mathbf{Q}$. However, these methods use fixed transforms--Hadamard matrices achieving optimal worst-case coherence $\\mu = 1/\\sqrt{n}$--that cannot adapt to specific weight distributions. We identify that different transformer layers exhibit distinct outlier patterns, motivating layer-adaptive rotations rather than one-size-fits-all approaches. We propose ButterflyQuant, which replaces Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens rotation angles. Unlike Hadamard's discrete $\\{+1, -1\\}$ entries that are non-differentiable and prohibit gradient-based learning, butterfly transforms' continuous parameterization enables smooth optimization while guaranteeing orthogonality by construction. This orthogonal constraint ensures theoretical guarantees in outlier suppression while achieving $O(n \\log n)$ computational complexity with only $\\frac{n \\log n}{2}$ learnable parameters. We further introduce a uniformity regularization on post-transformation activations to promote smoother distributions amenable to quantization. Learning requires only 128 calibration samples and converges in minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.",
    "authors": [
      "Bingxin Xu",
      "Zhen Dong",
      "Oussama Elachqar",
      "Yuzhang Shang"
    ],
    "published_date": "2025-09-11T17:59:51+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09679v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09677v1",
    "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs",
    "summary": "Does continued scaling of large language models (LLMs) yield diminishing returns? Real-world value often stems from the length of task an agent can complete. We start this work by observing the simple but counterintuitive fact that marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Then, we argue that failures of LLMs when simple tasks are made longer arise from mistakes in execution, rather than an inability to reason. We propose isolating execution capability, by explicitly providing the knowledge and plan needed to solve a long-horizon task. We find that larger models can correctly execute significantly more turns even when small models have 100\\% single-turn accuracy. We observe that the per-step accuracy of models degrades as the number of steps increases. This is not just due to long-context limitations -- curiously, we observe a self-conditioning effect -- models become more likely to make mistakes when the context contains their errors from prior turns. Self-conditioning does not reduce by just scaling the model size. In contrast, recent thinking models do not self-condition, and can also execute much longer tasks in a single turn. We conclude by benchmarking frontier thinking models on the length of task they can execute in a single turn. Overall, by focusing on the ability to execute, we hope to reconcile debates on how LLMs can solve complex reasoning problems yet fail at simple tasks when made longer, and highlight the massive benefits of scaling model size and sequential test-time compute for long-horizon tasks.",
    "authors": [
      "Akshit Sinha",
      "Arvindh Arun",
      "Shashwat Goel",
      "Steffen Staab",
      "Jonas Geiping"
    ],
    "published_date": "2025-09-11T17:59:34+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09677v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09674v1",
    "title": "SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning",
    "summary": "Vision-Language-Action (VLA) models have recently emerged as a powerful paradigm for robotic manipulation. Despite substantial progress enabled by large-scale pretraining and supervised fine-tuning (SFT), these models face two fundamental challenges: (i) the scarcity and high cost of large-scale human-operated robotic trajectories required for SFT scaling, and (ii) limited generalization to tasks involving distribution shift. Recent breakthroughs in Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can dramatically enhance step-by-step reasoning capabilities, raising a natural question: Can RL similarly improve the long-horizon step-by-step action planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL framework tailored for VLA models. Building upon veRL, we introduce VLA-specific trajectory sampling, scalable parallelization, multi-environment rendering, and optimized loss computation. When applied to OpenVLA-OFT, SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\\pi_0$ on RoboTwin 1.0\\&2.0 with the exploration-enhancing strategies we introduce. SimpleVLA-RL not only reduces dependence on large-scale data and enables robust generalization, but also remarkably surpasses SFT in real-world tasks. Moreover, we identify a novel phenomenon ``pushcut'' during RL training, wherein the policy discovers previously unseen patterns beyond those seen in the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL",
    "authors": [
      "Haozhan Li",
      "Yuxin Zuo",
      "Jiale Yu",
      "Yuhao Zhang",
      "Zhaohui Yang",
      "Kaiyan Zhang",
      "Xuekai Zhu",
      "Yuchen Zhang",
      "Tianxing Chen",
      "Ganqu Cui",
      "Dehui Wang",
      "Dingxiang Luo",
      "Yuchen Fan",
      "Youbang Sun",
      "Jia Zeng",
      "Jiangmiao Pang",
      "Shanghang Zhang",
      "Yu Wang",
      "Yao Mu",
      "Bowen Zhou",
      "Ning Ding"
    ],
    "published_date": "2025-09-11T17:59:17+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09674v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09675v1",
    "title": "CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm for enhancing the reasoning ability of Large Language Models (LLMs). Yet current RLVR methods often explore poorly, leading to premature convergence and entropy collapse. To address this challenge, we introduce Curiosity-Driven Exploration (CDE), a framework that leverages the model's own intrinsic sense of curiosity to guide exploration. We formalize curiosity with signals from both the actor and the critic: for the actor, we use perplexity over its generated response, and for the critic, we use the variance of value estimates from a multi-head architecture. Both signals serve as an exploration bonus within the RLVR framework to guide the model. Our theoretical analysis shows that the actor-wise bonus inherently penalizes overconfident errors and promotes diversity among correct responses; moreover, we connect the critic-wise bonus to the well-established count-based exploration bonus in RL. Empirically, our method achieves an approximate +3 point improvement over standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a calibration collapse mechanism within RLVR, shedding light on common LLM failure modes.",
    "authors": [
      "Runpeng Dai",
      "Linfeng Song",
      "Haolin Liu",
      "Zhenwen Liang",
      "Dian Yu",
      "Haitao Mi",
      "Zhaopeng Tu",
      "Rui Liu",
      "Tong Zheng",
      "Hongtu Zhu",
      "Dong Yu"
    ],
    "published_date": "2025-09-11T17:59:17+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09675v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09660v1",
    "title": "Steering MoE LLMs via Expert (De)Activation",
    "summary": "Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token through a subset of specialized Feed-Forward Networks (FFN), known as experts. We present SteerMoE, a framework for steering MoE models by detecting and controlling behavior-linked experts. Our detection method identifies experts with distinct activation patterns across paired inputs exhibiting contrasting behaviors. By selectively (de)activating such experts during inference, we control behaviors like faithfulness and safety without retraining or modifying weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to +20% and faithfulness by +27%. In adversarial attack mode, it drops safety by -41% alone, and -100% when combined with existing jailbreak methods, bypassing all safety guardrails and exposing a new dimension of alignment faking hidden within experts.",
    "authors": [
      "Mohsen Fayyaz",
      "Ali Modarressi",
      "Hanieh Deilamsalehy",
      "Franck Dernoncourt",
      "Ryan Rossi",
      "Trung Bui",
      "Hinrich Sch\u00fctze",
      "Nanyun Peng"
    ],
    "published_date": "2025-09-11T17:55:09+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09660v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09655v1",
    "title": "Feasibility-Guided Fair Adaptive Offline Reinforcement Learning for Medicaid Care Management",
    "summary": "We introduce Feasibility-Guided Fair Adaptive Reinforcement Learning (FG-FARL), an offline RL procedure that calibrates per-group safety thresholds to reduce harm while equalizing a chosen fairness target (coverage or harm) across protected subgroups. Using de-identified longitudinal trajectories from a Medicaid population health management program, we evaluate FG-FARL against behavior cloning (BC) and HACO (Hybrid Adaptive Conformal Offline RL; a global conformal safety baseline). We report off-policy value estimates with bootstrap 95% confidence intervals and subgroup disparity analyses with p-values. FG-FARL achieves comparable value to baselines while improving fairness metrics, demonstrating a practical path to safer and more equitable decision support.",
    "authors": [
      "Sanjay Basu",
      "Sadiq Y. Patel",
      "Parth Sheth",
      "Bhairavi Muralidharan",
      "Namrata Elamaran",
      "Aakriti Kinra",
      "Rajaie Batniji"
    ],
    "published_date": "2025-09-11T17:50:06+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09655v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09651v1",
    "title": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations",
    "summary": "We study question answering in the domain of radio regulations, a legally sensitive and high-stakes area. We propose a telecom-specific Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge, the first multiple-choice evaluation set for this domain, constructed from authoritative sources using automated filtering and human validation. To assess retrieval quality, we define a domain-specific retrieval metric, under which our retriever achieves approximately 97% accuracy. Beyond retrieval, our approach consistently improves generation accuracy across all tested models. In particular, while naively inserting documents without structured retrieval yields only marginal gains for GPT-4o (less than 1%), applying our pipeline results in nearly a 12% relative improvement. These findings demonstrate that carefully targeted grounding provides a simple yet strong baseline and an effective domain-specific solution for regulatory question answering. All code and evaluation scripts, along with our derived question-answer dataset, are available at https://github.com/Zakaria010/Radio-RAG.",
    "authors": [
      "Zakaria El Kassimi",
      "Fares Fourati",
      "Mohamed-Slim Alouini"
    ],
    "published_date": "2025-09-11T17:43:42+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09651v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09630v1",
    "title": "I Know Who Clones Your Code: Interpretable Smart Contract Similarity Detection",
    "summary": "Widespread reuse of open-source code in smart contract development boosts programming efficiency but significantly amplifies bug propagation across contracts, while dedicated methods for detecting similar smart contract functions remain very limited. Conventional abstract-syntax-tree (AST) based methods for smart contract similarity detection face challenges in handling intricate tree structures, which impedes detailed semantic comparison of code. Recent deep-learning based approaches tend to overlook code syntax and detection interpretability, resulting in suboptimal performance.   To fill this research gap, we introduce SmartDetector, a novel approach for computing similarity between smart contract functions, explainable at the fine-grained statement level. Technically, SmartDetector decomposes the AST of a smart contract function into a series of smaller statement trees, each reflecting a structural element of the source code. Then, SmartDetector uses a classifier to compute the similarity score of two functions by comparing each pair of their statement trees. To address the infinite hyperparameter space of the classifier, we mathematically derive a cosine-wise diffusion process to efficiently search optimal hyperparameters. Extensive experiments conducted on three large real-world datasets demonstrate that SmartDetector outperforms current state-of-the-art methods by an average improvement of 14.01% in F1-score, achieving an overall average F1-score of 95.88%.",
    "authors": [
      "Zhenguang Liu",
      "Lixun Ma",
      "Zhongzheng Mu",
      "Chengkun Wei",
      "Xiaojun Xu",
      "Yingying Jiao",
      "Kui Ren"
    ],
    "published_date": "2025-09-11T17:15:51+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09630v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09619v1",
    "title": "Functional Groups are All you Need for Chemically Interpretable Molecular Property Prediction",
    "summary": "Molecular property prediction using deep learning (DL) models has accelerated drug and materials discovery, but the resulting DL models often lack interpretability, hindering their adoption by chemists. This work proposes developing molecule representations using the concept of Functional Groups (FG) in chemistry. We introduce the Functional Group Representation (FGR) framework, a novel approach to encoding molecules based on their fundamental chemical substructures. Our method integrates two types of functional groups: those curated from established chemical knowledge (FG), and those mined from a large molecular corpus using sequential pattern mining (MFG). The resulting FGR framework encodes molecules into a lower-dimensional latent space by leveraging pre-training on a large dataset of unlabeled molecules. Furthermore, the proposed framework allows the inclusion of 2D structure-based descriptors of molecules. We demonstrate that the FGR framework achieves state-of-the-art performance on a diverse range of 33 benchmark datasets spanning physical chemistry, biophysics, quantum mechanics, biological activity, and pharmacokinetics while enabling chemical interpretability. Crucially, the model's representations are intrinsically aligned with established chemical principles, allowing chemists to directly link predicted properties to specific functional groups and facilitating novel insights into structure-property relationships. Our work presents a significant step toward developing high-performing, chemically interpretable DL models for molecular discovery.",
    "authors": [
      "Roshan Balaji",
      "Joe Bobby",
      "Nirav Pravinbhai Bhatt"
    ],
    "published_date": "2025-09-11T17:01:31+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09619v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09616v1",
    "title": "Explaining Concept Drift through the Evolution of Group Counterfactuals",
    "summary": "Machine learning models in dynamic environments often suffer from concept drift, where changes in the data distribution degrade performance. While detecting this drift is a well-studied topic, explaining how and why the model's decision-making logic changes still remains a significant challenge. In this paper, we introduce a novel methodology to explain concept drift by analyzing the temporal evolution of group-based counterfactual explanations (GCEs). Our approach tracks shifts in the GCEs' cluster centroids and their associated counterfactual action vectors before and after a drift. These evolving GCEs act as an interpretable proxy, revealing structural changes in the model's decision boundary and its underlying rationale. We operationalize this analysis within a three-layer framework that synergistically combines insights from the data layer (distributional shifts), the model layer (prediction disagreement), and our proposed explanation layer. We show that such holistic view allows for a more comprehensive diagnosis of drift, making it possible to distinguish between different root causes, such as a spatial data shift versus a re-labeling of concepts.",
    "authors": [
      "Ignacy St\u0119pka",
      "Jerzy Stefanowski"
    ],
    "published_date": "2025-09-11T16:58:34+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09616v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09614v1",
    "title": "LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering",
    "summary": "The emergence of long-context language models with context windows extending to millions of tokens has created new opportunities for sophisticated code understanding and software development evaluation. We propose LoCoBench, a comprehensive benchmark specifically designed to evaluate long-context LLMs in realistic, complex software development scenarios. Unlike existing code evaluation benchmarks that focus on single-function completion or short-context tasks, LoCoBench addresses the critical evaluation gap for long-context capabilities that require understanding entire codebases, reasoning across multiple files, and maintaining architectural consistency across large-scale software systems. Our benchmark provides 8,000 evaluation scenarios systematically generated across 10 programming languages, with context lengths spanning 10K to 1M tokens, a 100x variation that enables precise assessment of long-context performance degradation in realistic software development settings. LoCoBench introduces 8 task categories that capture essential long-context capabilities: architectural understanding, cross-file refactoring, multi-session development, bug investigation, feature implementation, code comprehension, integration testing, and security analysis. Through a 5-phase pipeline, we create diverse, high-quality scenarios that challenge LLMs to reason about complex codebases at unprecedented scale. We introduce a comprehensive evaluation framework with 17 metrics across 4 dimensions, including 8 new evaluation metrics, combined in a LoCoBench Score (LCBS). Our evaluation of state-of-the-art long-context models reveals substantial performance gaps, demonstrating that long-context understanding in complex software development represents a significant unsolved challenge that demands more attention. LoCoBench is released at: https://github.com/SalesforceAIResearch/LoCoBench.",
    "authors": [
      "Jielin Qiu",
      "Zuxin Liu",
      "Zhiwei Liu",
      "Rithesh Murthy",
      "Jianguo Zhang",
      "Haolin Chen",
      "Shiyu Wang",
      "Ming Zhu",
      "Liangwei Yang",
      "Juntao Tan",
      "Zhepeng Cen",
      "Cheng Qian",
      "Shelby Heinecke",
      "Weiran Yao",
      "Silvio Savarese",
      "Caiming Xiong",
      "Huan Wang"
    ],
    "published_date": "2025-09-11T16:55:04+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09614v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09611v1",
    "title": "ReBaNO: Reduced Basis Neural Operator Mitigating Generalization Gaps and Achieving Discretization Invariance",
    "summary": "We propose a novel data-lean operator learning algorithm, the Reduced Basis Neural Operator (ReBaNO), to solve a group of PDEs with multiple distinct inputs. Inspired by the Reduced Basis Method and the recently introduced Generative Pre-Trained Physics-Informed Neural Networks, ReBaNO relies on a mathematically rigorous greedy algorithm to build its network structure offline adaptively from the ground up. Knowledge distillation via task-specific activation function allows ReBaNO to have a compact architecture requiring minimal computational cost online while embedding physics. In comparison to state-of-the-art operator learning algorithms such as PCA-Net, DeepONet, FNO, and CNO, numerical results demonstrate that ReBaNO significantly outperforms them in terms of eliminating/shrinking the generalization gap for both in- and out-of-distribution tests and being the only operator learning algorithm achieving strict discretization invariance.",
    "authors": [
      "Haolan Zheng",
      "Yanlai Chen",
      "Jiequn Han",
      "Yue Yu"
    ],
    "published_date": "2025-09-11T16:52:54+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09611v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09610v1",
    "title": "Mechanistic Learning with Guided Diffusion Models to Predict Spatio-Temporal Brain Tumor Growth",
    "summary": "Predicting the spatio-temporal progression of brain tumors is essential for guiding clinical decisions in neuro-oncology. We propose a hybrid mechanistic learning framework that combines a mathematical tumor growth model with a guided denoising diffusion implicit model (DDIM) to synthesize anatomically feasible future MRIs from preceding scans. The mechanistic model, formulated as a system of ordinary differential equations, captures temporal tumor dynamics including radiotherapy effects and estimates future tumor burden. These estimates condition a gradient-guided DDIM, enabling image synthesis that aligns with both predicted growth and patient anatomy. We train our model on the BraTS adult and pediatric glioma datasets and evaluate on 60 axial slices of in-house longitudinal pediatric diffuse midline glioma (DMG) cases. Our framework generates realistic follow-up scans based on spatial similarity metrics. It also introduces tumor growth probability maps, which capture both clinically relevant extent and directionality of tumor growth as shown by 95th percentile Hausdorff Distance. The method enables biologically informed image generation in data-limited scenarios, offering generative-space-time predictions that account for mechanistic priors.",
    "authors": [
      "Daria Laslo",
      "Efthymios Georgiou",
      "Marius George Linguraru",
      "Andreas Rauschecker",
      "Sabine Muller",
      "Catherine R. Jutzeler",
      "Sarah Bruningk"
    ],
    "published_date": "2025-09-11T16:52:09+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09610v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09599v1",
    "title": "Conditioning on PDE Parameters to Generalise Deep Learning Emulation of Stochastic and Chaotic Dynamics",
    "summary": "We present a deep learning emulator for stochastic and chaotic spatio-temporal systems, explicitly conditioned on the parameter values of the underlying partial differential equations (PDEs). Our approach involves pre-training the model on a single parameter domain, followed by fine-tuning on a smaller, yet diverse dataset, enabling generalisation across a broad range of parameter values. By incorporating local attention mechanisms, the network is capable of handling varying domain sizes and resolutions. This enables computationally efficient pre-training on smaller domains while requiring only a small additional dataset to learn how to generalise to larger domain sizes. We demonstrate the model's capabilities on the chaotic Kuramoto-Sivashinsky equation and stochastically-forced beta-plane turbulence, showcasing its ability to capture phenomena at interpolated parameter values. The emulator provides significant computational speed-ups over conventional numerical integration, facilitating efficient exploration of parameter space, while a probabilistic variant of the emulator provides uncertainty quantification, allowing for the statistical study of rare events.",
    "authors": [
      "Ira J. S. Shokar",
      "Rich R. Kerswell",
      "Peter H. Haynes"
    ],
    "published_date": "2025-09-11T16:37:45+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09599v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09597v1",
    "title": "Graph Alignment via Dual-Pass Spectral Encoding and Latent Space Communication",
    "summary": "Graph alignment-the problem of identifying corresponding nodes across multiple graphs-is fundamental to numerous applications. Most existing unsupervised methods embed node features into latent representations to enable cross-graph comparison without ground-truth correspondences. However, these methods suffer from two critical limitations: the degradation of node distinctiveness due to oversmoothing in GNN-based embeddings, and the misalignment of latent spaces across graphs caused by structural noise, feature heterogeneity, and training instability, ultimately leading to unreliable node correspondences. We propose a novel graph alignment framework that simultaneously enhances node distinctiveness and enforces geometric consistency across latent spaces. Our approach introduces a dual-pass encoder that combines low-pass and high-pass spectral filters to generate embeddings that are both structure-aware and highly discriminative. To address latent space misalignment, we incorporate a geometry-aware functional map module that learns bijective and isometric transformations between graph embeddings, ensuring consistent geometric relationships across different representations. Extensive experiments on graph benchmarks demonstrate that our method consistently outperforms existing unsupervised alignment baselines, exhibiting superior robustness to structural inconsistencies and challenging alignment scenarios. Additionally, comprehensive evaluation on vision-language benchmarks using diverse pretrained models shows that our framework effectively generalizes beyond graph domains, enabling unsupervised alignment of vision and language representations.",
    "authors": [
      "Maysam Behmanesh",
      "Erkan Turan",
      "Maks Ovsjanikov"
    ],
    "published_date": "2025-09-11T16:36:16+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09597v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09594v1",
    "title": "ObjectReact: Learning Object-Relative Control for Visual Navigation",
    "summary": "Visual navigation using only a single camera and a topological map has recently become an appealing alternative to methods that require additional sensors and 3D maps. This is typically achieved through an \"image-relative\" approach to estimating control from a given pair of current observation and subgoal image. However, image-level representations of the world have limitations because images are strictly tied to the agent's pose and embodiment. In contrast, objects, being a property of the map, offer an embodiment- and trajectory-invariant world representation. In this work, we present a new paradigm of learning \"object-relative\" control that exhibits several desirable characteristics: a) new routes can be traversed without strictly requiring to imitate prior experience, b) the control prediction problem can be decoupled from solving the image matching problem, and c) high invariance can be achieved in cross-embodiment deployment for variations across both training-testing and mapping-execution settings. We propose a topometric map representation in the form of a \"relative\" 3D scene graph, which is used to obtain more informative object-level global path planning costs. We train a local controller, dubbed \"ObjectReact\", conditioned directly on a high-level \"WayObject Costmap\" representation that eliminates the need for an explicit RGB input. We demonstrate the advantages of learning object-relative control over its image-relative counterpart across sensor height variations and multiple navigation tasks that challenge the underlying spatial understanding capability, e.g., navigating a map trajectory in the reverse direction. We further show that our sim-only policy is able to generalize well to real-world indoor environments. Code and supplementary material are accessible via project page: https://object-react.github.io/",
    "authors": [
      "Sourav Garg",
      "Dustin Craggs",
      "Vineeth Bhat",
      "Lachlan Mares",
      "Stefan Podgorski",
      "Madhava Krishna",
      "Feras Dayoub",
      "Ian Reid"
    ],
    "published_date": "2025-09-11T16:34:17+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09594v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09593v1",
    "title": "Fluent but Unfeeling: The Emotional Blind Spots of Language Models",
    "summary": "The versatility of Large Language Models (LLMs) in natural language understanding has made them increasingly popular in mental health research. While many studies explore LLMs' capabilities in emotion recognition, a critical gap remains in evaluating whether LLMs align with human emotions at a fine-grained level. Existing research typically focuses on classifying emotions into predefined, limited categories, overlooking more nuanced expressions. To address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit communities featuring 251 fine-grained, self-disclosed emotion labels. Our comprehensive evaluation framework examines predicted emotion terms and decomposes them into eight basic emotions using established emotion theories, enabling a fine-grained comparison. Systematic testing of prevalent LLMs under various prompt settings reveals that accurately predicting emotions that align with human self-disclosed emotions remains challenging. Qualitative analysis further shows that while certain LLMs generate emotion terms consistent with established emotion theories and definitions, they sometimes fail to capture contextual cues as effectively as human self-disclosures. These findings highlight the limitations of LLMs in fine-grained emotion alignment and offer insights for future research aimed at enhancing their contextual understanding.",
    "authors": [
      "Bangzhao Shu",
      "Isha Joshi",
      "Melissa Karnaze",
      "Anh C. Pham",
      "Ishita Kakkar",
      "Sindhu Kothe",
      "Arpine Hovasapian",
      "Mai ElSherief"
    ],
    "published_date": "2025-09-11T16:31:13+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09593v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09583v1",
    "title": "Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking",
    "summary": "Social connection is a vital part of learning, yet online course environments present barriers to the organic formation of social groups. SAMI offers one solution by facilitating student connections, but its effectiveness is constrained by an incomplete Theory of Mind, limiting its ability to create an effective mental model of a student. One facet of this is its inability to intuit personality, which may influence the relevance of its recommendations. To explore this, we propose a personality detection model utilizing GPTs zero-shot capability to infer Big-Five personality traits from forum introduction posts, often encouraged in online courses. We benchmark its performance against established models, demonstrating its efficacy in this task. Furthermore, we integrate this model into SAMIs entity-based matchmaking system, enabling personality-informed social recommendations. Initial integration suggests personality traits can complement existing matching factors, though additional evaluation is required to determine their full impact on student engagement and match quality.",
    "authors": [
      "Brittany Harbison",
      "Samuel Taubman",
      "Travis Taylor",
      "Ashok. K. Goel"
    ],
    "published_date": "2025-09-11T16:19:59+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09583v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09564v1",
    "title": "What Does Normal Even Mean? Evaluating Benign Traffic in Intrusion Detection Datasets",
    "summary": "Supervised machine learning techniques rely on labeled data to achieve high task performance, but this requires the labels to capture some meaningful differences in the underlying data structure. For training network intrusion detection algorithms, most datasets contain a series of attack classes and a single large benign class which captures all non-attack network traffic. A review of intrusion detection papers and guides that explicitly state their data preprocessing steps identified that the majority took the labeled categories of the dataset at face value when training their algorithms. The present paper evaluates the structure of benign traffic in several common intrusion detection datasets (NSL-KDD, UNSW-NB15, and CIC-IDS 2017) and determines whether there are meaningful sub-categories within this traffic which may improve overall multi-classification performance using common machine learning techniques. We present an overview of some unsupervised clustering techniques (e.g., HDBSCAN, Mean Shift Clustering) and show how they differentially cluster the benign traffic space.",
    "authors": [
      "Meghan Wilkinson",
      "Robert H Thomson"
    ],
    "published_date": "2025-09-11T15:55:21+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09564v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09560v1",
    "title": "Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution",
    "summary": "Embodied AI systems operate in dynamic environments, requiring seamless integration of perception and generation modules to process high-frequency input and output demands. Traditional sequential computation patterns, while effective in ensuring accuracy, face significant limitations in achieving the necessary \"thinking\" frequency for real-world applications. In this work, we present Auras, an algorithm-system co-designed inference framework to optimize the inference frequency of embodied AI agents. Auras disaggregates the perception and generation and provides controlled pipeline parallelism for them to achieve high and stable throughput. Faced with the data staleness problem that appears when the parallelism is increased, Auras establishes a public context for perception and generation to share, thereby promising the accuracy of embodied agents. Experimental results show that Auras improves throughput by 2.54x on average while achieving 102.7% of the original accuracy, demonstrating its efficacy in overcoming the constraints of sequential computation and providing high throughput.",
    "authors": [
      "Shulai Zhang",
      "Ao Xu",
      "Quan Chen",
      "Han Zhao",
      "Weihao Cui",
      "Ningxin Zheng",
      "Haibin Lin",
      "Xin Liu",
      "Minyi Guo"
    ],
    "published_date": "2025-09-11T15:51:43+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09560v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09558v1",
    "title": "Invisible Attributes, Visible Biases: Exploring Demographic Shortcuts in MRI-based Alzheimer's Disease Classification",
    "summary": "Magnetic resonance imaging (MRI) is the gold standard for brain imaging. Deep learning (DL) algorithms have been proposed to aid in the diagnosis of diseases such as Alzheimer's disease (AD) from MRI scans. However, DL algorithms can suffer from shortcut learning, in which spurious features, not directly related to the output label, are used for prediction. When these features are related to protected attributes, they can lead to performance bias against underrepresented protected groups, such as those defined by race and sex. In this work, we explore the potential for shortcut learning and demographic bias in DL based AD diagnosis from MRI. We first investigate if DL algorithms can identify race or sex from 3D brain MRI scans to establish the presence or otherwise of race and sex based distributional shifts. Next, we investigate whether training set imbalance by race or sex can cause a drop in model performance, indicating shortcut learning and bias. Finally, we conduct a quantitative and qualitative analysis of feature attributions in different brain regions for both the protected attribute and AD classification tasks. Through these experiments, and using multiple datasets and DL models (ResNet and SwinTransformer), we demonstrate the existence of both race and sex based shortcut learning and bias in DL based AD classification. Our work lays the foundation for fairer DL diagnostic tools in brain MRI. The code is provided at https://github.com/acharaakshit/ShortMR",
    "authors": [
      "Akshit Achara",
      "Esther Puyol Anton",
      "Alexander Hammers",
      "Andrew P. King"
    ],
    "published_date": "2025-09-11T15:48:30+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09558v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09552v1",
    "title": "An improved educational competition optimizer with multi-covariance learning operators for global optimization problems",
    "summary": "The educational competition optimizer is a recently introduced metaheuristic algorithm inspired by human behavior, originating from the dynamics of educational competition within society. Nonetheless, ECO faces constraints due to an imbalance between exploitation and exploration, rendering it susceptible to local optima and demonstrating restricted effectiveness in addressing complex optimization problems. To address these limitations, this study presents an enhanced educational competition optimizer (IECO-MCO) utilizing multi-covariance learning operators. In IECO, three distinct covariance learning operators are introduced to improve the performance of ECO. Each operator effectively balances exploitation and exploration while preventing premature convergence of the population. The effectiveness of IECO is assessed through benchmark functions derived from the CEC 2017 and CEC 2022 test suites, and its performance is compared with various basic and improved algorithms across different categories. The results demonstrate that IECO-MCO surpasses the basic ECO and other competing algorithms in convergence speed, stability, and the capability to avoid local optima. Furthermore, statistical analyses, including the Friedman test, Kruskal-Wallis test, and Wilcoxon rank-sum test, are conducted to validate the superiority of IECO-MCO over the compared algorithms. Compared with the basic algorithm (improved algorithm), IECO-MCO achieved an average ranking of 2.213 (2.488) on the CE2017 and CEC2022 test suites. Additionally, the practical applicability of the proposed IECO-MCO algorithm is verified by solving constrained optimization problems. The experimental outcomes demonstrate the superior performance of IECO-MCO in tackling intricate optimization problems, underscoring its robustness and practical effectiveness in real-world scenarios.",
    "authors": [
      "Baoqi Zhao",
      "Xiong Yang",
      "Hoileong Lee",
      "Bowen Dong"
    ],
    "published_date": "2025-09-11T15:41:14+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09552v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09550v1",
    "title": "Finite Scalar Quantization Enables Redundant and Transmission-Robust Neural Audio Compression at Low Bit-rates",
    "summary": "Neural Audio Codecs (NACs) have become increasingly adopted in speech processing tasks due to their excellent rate-distortion performance and compatibility with Large Language Models (LLMs) as discrete feature representations for audio generation. While most existing codecs rely on Residual Vector Quantization (RVQ), Finite Scalar Quantization (FSQ) has recently emerged as a compelling alternative that simplifies training and natively supports single codebooks. We introduce NeuCodec, an FSQ-based NAC, and show that FSQ encodes baked-in redundancy which produces an encoding which is robust when transmitted through noisy channels. First, through an encoder distillation experiment, we show that two different encoders can learn to encode identical audio into vastly different code sequences whilst maintaining comparable reconstruction quality with the same quantizer and decoder. Second, we demonstrate that FSQ has vastly superior bit-level perturbation robustness by comparing the performance of RVQ and FSQ codecs when simulating the transmission of code sequences through a noisy channel.",
    "authors": [
      "Harry Julia",
      "Rachel Beeson",
      "Lohith Konathala",
      "Johanna Ulin",
      "Jiameng Gao"
    ],
    "published_date": "2025-09-11T15:39:59+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09550v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09547v1",
    "title": "Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders",
    "summary": "Video diffusion models have advanced rapidly in the recent years as a result of series of architectural innovations (e.g., diffusion transformers) and use of novel training objectives (e.g., flow matching). In contrast, less attention has been paid to improving the feature representation power of such models. In this work, we show that training video diffusion models can benefit from aligning the intermediate features of the video generator with feature representations of pre-trained vision encoders. We propose a new metric and conduct an in-depth analysis of various vision encoders to evaluate their discriminability and temporal consistency, thereby assessing their suitability for video feature alignment. Based on the analysis, we present Align4Gen which provides a novel multi-feature fusion and alignment method integrated into video diffusion model training. We evaluate Align4Gen both for unconditional and class-conditional video generation tasks and show that it results in improved video generation as quantified by various metrics. Full video results are available on our project page: https://align4gen.github.io/align4gen/",
    "authors": [
      "Dohun Lee",
      "Hyeonho Jeong",
      "Jiwook Kim",
      "Duygu Ceylan",
      "Jong Chul Ye"
    ],
    "published_date": "2025-09-11T15:39:27+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09547v1"
  },
  {
    "id": "http://arxiv.org/abs/2509.09541v1",
    "title": "Compositional Concept Generalization with Variational Quantum Circuits",
    "summary": "Compositional generalization is a key facet of human cognition, but lacking in current AI tools such as vision-language models. Previous work examined whether a compositional tensor-based sentence semantics can overcome the challenge, but led to negative results. We conjecture that the increased training efficiency of quantum models will improve performance in these tasks. We interpret the representations of compositional tensor-based models in Hilbert spaces and train Variational Quantum Circuits to learn these representations on an image captioning task requiring compositional generalization. We used two image encoding techniques: a multi-hot encoding (MHE) on binary image vectors and an angle/amplitude encoding on image vectors taken from the vision-language model CLIP. We achieve good proof-of-concept results using noisy MHE encodings. Performance on CLIP image vectors was more mixed, but still outperformed classical compositional models.",
    "authors": [
      "Hala Hawashin",
      "Mina Abbaszadeh",
      "Nicholas Joseph",
      "Beth Pearson",
      "Martha Lewis",
      "Mehrnoosh sadrzadeh"
    ],
    "published_date": "2025-09-11T15:34:33+00:00",
    "pdf_url": "http://arxiv.org/pdf/2509.09541v1"
  }
]